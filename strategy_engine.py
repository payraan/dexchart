import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from database_manager import db_manager
from analysis_engine import AnalysisEngine
# --- Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯: Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ú©Ø±Ø¯Ù† ØªÙ†Ø¸ÛŒÙ…Ø§Øª ---
from config import TradingConfig 

class StrategyEngine:
    def __init__(self):
        self.analysis_engine = AnalysisEngine()
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù„Ø§Ú¯Ø± Ø¨Ù‡ Ø¬Ø§ÛŒ Ù¾Ø±ÛŒÙ†Øª
        self.logger = logging.getLogger(__name__)
 
    async def select_optimal_timeframe(self, pool_id):
        """
        Ø§Ù†ØªØ®Ø§Ø¨ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù…Ø± ÙˆØ§Ù‚Ø¹ÛŒ ØªÙˆÚ©Ù†
        """
        try:
            # Ø§ÙˆÙ„ Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ 1 Ø³Ø§Ø¹ØªÙ‡ Ø¹Ù…Ø± Ø±Ùˆ ØªØ®Ù…ÛŒÙ† Ø¨Ø²Ù†ÛŒÙ…
            df_1h = await self.analysis_engine.get_historical_data(
                pool_id, "hour", "1", limit=500
            )
            
            if df_1h is None or df_1h.empty:
                return None, None
            
            # Ø§Ú¯Ø± 500 Ú©Ù†Ø¯Ù„ 1 Ø³Ø§Ø¹ØªÙ‡ Ø¯Ø§Ø±ÛŒÙ… = Ø­Ø¯Ø§Ù‚Ù„ 20 Ø±ÙˆØ² Ø¹Ù…Ø±
            if len(df_1h) >= 500:
                # ØªÙˆÚ©Ù† Ù‚Ø¯ÛŒÙ…ÛŒ - Ú†Ú© Ú©Ù†ÛŒÙ… Ú†Ù‚Ø¯Ø± Ù‚Ø¯ÛŒÙ…ÛŒÙ‡
                df_daily = await self.analysis_engine.get_historical_data(
                    pool_id, "day", "1", limit=100
                )
                
                if df_daily is not None and len(df_daily) >= 90:
                    # Ø¨ÛŒØ´ Ø§Ø² 90 Ø±ÙˆØ² = 12H chart
                    timeframe_data = ("hour", "12")
                    self.logger.info(f"ğŸ“‰ Old token (90+ days) â†’ Using 12H chart")
                elif df_daily is not None and len(df_daily) >= 30:
                    # 30-90 Ø±ÙˆØ² = 4H chart  
                    timeframe_data = ("hour", "4")
                    self.logger.info(f"ğŸ“Š Medium age token (30-90 days) â†’ Using 4H chart")
                else:
                    # 20-30 Ø±ÙˆØ² = 1H chart
                    timeframe_data = ("hour", "1")
                    self.logger.info(f"ğŸ“ˆ Recent token (20-30 days) â†’ Using 1H chart")
            else:
                # Ú©Ù…ØªØ± Ø§Ø² 500 Ú©Ù†Ø¯Ù„ 1 Ø³Ø§Ø¹ØªÙ‡
                hours_available = len(df_1h)
                days_available = hours_available / 24
                
                if days_available < 1:  # Ú©Ù…ØªØ± Ø§Ø² 1 Ø±ÙˆØ²
                    timeframe_data = ("minute", "5")
                    self.logger.info(f"ğŸ†• Very new token ({hours_available}h) â†’ Using 5M chart")
                elif days_available < 3:  # 1-3 Ø±ÙˆØ²
                    timeframe_data = ("minute", "15")
                    self.logger.info(f"ğŸ“± New token ({days_available:.1f} days) â†’ Using 15M chart")
                else:  # 3-20 Ø±ÙˆØ²
                    timeframe_data = ("hour", "1")
                    self.logger.info(f"ğŸ“ˆ Recent token ({days_available:.1f} days) â†’ Using 1H chart")
            
            return timeframe_data, df_1h
            
        except Exception as e:
            self.logger.error(f"Error in select_optimal_timeframe: {e}")
            return ("hour", "4"), None

    async def detect_breakout_signal(self, analysis_result, token_address):
        """New breakout detection using pre-analyzed data"""
        if not analysis_result:
            return None
            
        metadata = analysis_result['metadata']
        symbol = metadata['symbol']
        pool_id = metadata['pool_id']
        
        self.logger.info(f"ğŸ”„ [L1-START] Analysing {symbol} using pre-computed data")
            
        current_price = analysis_result['raw_data']['current_price']
        supply_zones = analysis_result['technical_levels']['zones']['supply']
        demand_zones = analysis_result['technical_levels']['zones']['demand']
        origin_zone = analysis_result['technical_levels']['zones'].get('origin')
        fibonacci_data = analysis_result['technical_levels']['fibonacci']
        
        # Ø¨Ø±Ø±Ø³ÛŒ Origin Zone Ø¨Ø±Ø§ÛŒ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
        if origin_zone and current_price > 0:
            zone_bottom = origin_zone['zone_bottom']
            zone_top = origin_zone['zone_top']
            
            # Ø§Ú¯Ø± Ù‚ÛŒÙ…Øª Ø¨Ù‡ Origin Zone Ø¨Ø±Ú¯Ø´ØªÙ‡
            if zone_bottom <= current_price <= zone_top * 1.1:
                self.logger.info(f"ğŸ’ {symbol}: Testing Origin Zone at ${current_price:.6f}")
                signal = {
                    'signal_type': 'ORIGIN_RETEST',
                    'token_address': token_address,
                    'pool_id': pool_id,
                    'symbol': symbol,
                    'current_price': current_price,
                    'zone_score': 10.0,  # Origin Zone Ù‡Ù…ÛŒØ´Ù‡ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§
                    'final_score': 10.0,
                    'support_level': zone_bottom,
                    'timestamp': datetime.now().isoformat()
                }
                signal['analysis_result'] = analysis_result
                return signal

        signal = self._check_confluence_signals(
            current_price, supply_zones, demand_zones, fibonacci_data,
            token_address, pool_id, symbol
        )
        
        if signal:
            signal['analysis_result'] = analysis_result
            self.logger.info(f"ğŸš€âœ… [L1-SUCCESS] Signal found for {symbol}!")
            return signal
            
        self.logger.info(f"ğŸ”µ [L1-INFO] No signal found for {symbol}")
        return None

    def _check_confluence_signals(self, current_price, supply_zones, demand_zones,
                                fibonacci_data, token_address, pool_id, symbol):
        """
        Checks for signals using new zone structure
        """
        ZONE_SCORE_MIN = TradingConfig.ZONE_SCORE_MIN
        PROXIMITY_THRESHOLD = TradingConfig.PROXIMITY_THRESHOLD

        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø§ÙˆÙ…Øªâ€ŒÙ‡Ø§ (Supply Zones)
        for zone in supply_zones:
            # ÙÛŒÙ„ØªØ± zones Ù†Ø§Ù…Ù†Ø·Ù‚ÛŒ: supply zone Ø¨Ø§ÛŒØ¯ Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ù‚ÛŒÙ…Øª Ø¨Ø§Ø´Ù‡
            if zone['level_price'] < current_price:
                continue
            if zone.get('score', 0) < ZONE_SCORE_MIN:
                continue
        
            zone_price = zone['level_price']
            final_score = self._calculate_confluence_score(zone, zone_price, fibonacci_data)

            # ÙÙ‚Ø· Ø¨Ø¹Ø¯ Ø§Ø² Ø´Ú©Ø³Øª Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø¯Ù‡
            if current_price > zone_price:
                proximity_above = (current_price - zone_price) / zone_price
                if proximity_above < 0.08:  # ØªØ§ 8% Ø¨Ø¹Ø¯ Ø§Ø² Ø´Ú©Ø³Øª
                    return self._create_signal_dict('resistance_breakout', locals(), final_score)

        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ù…Ø§ÛŒØªâ€ŒÙ‡Ø§ (Demand Zones)
        for zone in demand_zones:
            # ÙÛŒÙ„ØªØ± zones Ù†Ø§Ù…Ù†Ø·Ù‚ÛŒ: demand zone Ø¨Ø§ÛŒØ¯ Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø² Ù‚ÛŒÙ…Øª Ø¨Ø§Ø´Ù‡
            if zone['level_price'] > current_price:
                continue
            if zone.get('score', 0) < ZONE_SCORE_MIN:
                continue

            zone_price = zone['level_price']
            proximity = abs(current_price - zone_price) / zone_price

            if proximity < PROXIMITY_THRESHOLD:
                final_score = self._calculate_confluence_score(zone, zone_price, fibonacci_data)
                if final_score < 7.0:
                    continue
                return self._create_signal_dict('support_test', locals(), final_score)

        return None

    def _create_signal_dict(self, signal_type, local_vars, final_score):
       """Helper function to create a consistent signal dictionary."""
       from datetime import datetime
       zone = local_vars['zone']
       current_price = local_vars['current_price']
       zone_price = zone['level_price']

       signal = {
           'signal_type': signal_type,
           'token_address': local_vars['token_address'],
           'pool_id': local_vars['pool_id'],
           'symbol': local_vars['symbol'],
           'current_price': current_price,
           'zone_score': zone['score'],
           'final_score': final_score,
           'timestamp': datetime.now().isoformat()
       }

       # ÙÙ‚Ø· level Ù…Ù†Ø§Ø³Ø¨ Ø±Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
       if 'resistance' in signal_type or 'breakout' in signal_type:
           signal['level_broken'] = zone_price
       elif 'support' in signal_type or 'retest' in signal_type:
           signal['support_level'] = zone_price

       return signal

    def _calculate_confluence_score(self, zone, zone_price, fibonacci_data):
        """Calculate confluence score between a zone and fibonacci levels."""
        zone_base_score = zone['score']
        fibonacci_bonus = 0.0
        
        if fibonacci_data and fibonacci_data.get('levels'):
            key_fib_levels = [0.382, 0.5, 0.618]
            for fib_level in key_fib_levels:
                if fib_level in fibonacci_data['levels']:
                    fib_price = fibonacci_data['levels'][fib_level]
                    # --- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù‚Ø¯Ø§Ø± TradingConfig ---
                    if abs(zone_price - fib_price) / zone_price < TradingConfig.FIBONACCI_TOLERANCE:
                        fibonacci_bonus = 2.0 # Ø§ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ù‡Ù… Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Config Ù…Ù†ØªÙ‚Ù„ Ø´ÙˆØ¯
                        break
        
        trend_bonus = 0.5 # Ø§ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ù‡Ù… Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Config Ù…Ù†ØªÙ‚Ù„ Ø´ÙˆØ¯
        
        return zone_base_score + fibonacci_bonus + trend_bonus

    async def save_alert(self, signal):
        """Save alert to the database, including the specific level price."""
        level_price = signal.get('level_broken', signal.get('support_level', 0))
        current_price = signal['current_price']
        
        if hasattr(level_price, 'item'): level_price = level_price.item()
        if hasattr(current_price, 'item'): current_price = current_price.item()
            
        level_price = float(level_price) if level_price is not None else 0.0
        current_price = float(current_price)
        
        params = (
            signal['token_address'], signal['signal_type'], signal['timestamp'],
            current_price, level_price
        )
        placeholder = "%s" if db_manager.is_postgres else "?"
        query = f'''INSERT INTO alert_history (token_address, signal_type, timestamp, price_at_alert, level_price)
                    VALUES ({placeholder}, {placeholder}, {placeholder}, {placeholder}, {placeholder})'''
        try:
            db_manager.execute(query, params)
            self.logger.info(f"ğŸ’¾ Alert for {signal['symbol']} at level {level_price:.6f} saved.")
        except Exception as e:
            self.logger.error(f"Error in save_alert for {signal['symbol']}: {e}")

    # Ú©Ø¯ ØªØ§Ø¨Ø¹ has_recent_alert Ú©Ù‡ Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡ Ù‚Ø¨Ù„ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯ØŒ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø§ÛŒØ¯ Ù‚Ø±Ø§Ø± Ú¯ÛŒØ±Ø¯
    # Ø¯Ø± strategy_engine.py
    async def has_recent_alert(self, signal, cooldown_hours=None):
        """
        Checks for recent alerts. Supports dynamic cooldowns for different signal types.
        """
        from datetime import datetime, timedelta

        # --- Ø±ÙˆØªØ± Cooldown ---
        signal_type = signal.get('signal_type', '')
       
        if signal_type.startswith('GEM_'):
            # Cooldown Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ø±ÛŒØ¹ Gem
            cooldown_hours = 0.5  # 30 Ø¯Ù‚ÛŒÙ‚Ù‡
        elif cooldown_hours is None:
            # Cooldown Ù¾ÙˆÛŒØ§ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªÚ©Ù†ÛŒÚ©Ø§Ù„
            try:
                timeframe = signal['analysis_result']['metadata']['timeframe']
                if timeframe == 'minute':
                    cooldown_hours = 1
                elif timeframe == 'hour':
                    cooldown_hours = TradingConfig.COOLDOWN_HOURS
                else:  # â† Ø§ÛŒÙ† Ø®Ø· Ù…ÙÙ‚ÙˆØ¯ Ø¨ÙˆØ¯!
                    cooldown_hours = TradingConfig.COOLDOWN_HOURS
            except (KeyError, TypeError):
                # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§
                cooldown_hours = TradingConfig.COOLDOWN_HOURS

        # --- Ù¾Ø§ÛŒØ§Ù† Ø±ÙˆØªØ± Cooldown ---
    
        level_price = signal.get('level_broken', signal.get('support_level'))
    
        # Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Gem Ú©Ù‡ level Ù†Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø§Ø² Ø®ÙˆØ¯ Ø¢Ø¯Ø±Ø³ ØªÙˆÚ©Ù† Ø¨Ø±Ø§ÛŒ Cooldown Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        if signal_type.startswith('GEM_'):
            placeholder = "%s" if db_manager.is_postgres else "?"
            cooldown_time = (datetime.now() - timedelta(hours=cooldown_hours)).isoformat()
            query = f"""SELECT timestamp FROM alert_history 
                        WHERE token_address = {placeholder} AND signal_type = {placeholder} AND timestamp > {placeholder}
                        LIMIT 1"""
            params = (signal['token_address'], signal_type, cooldown_time)
        else:
            # Ù…Ù†Ø·Ù‚ ÙØ¹Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø³Ø·Ø­ Ù‚ÛŒÙ…Øª
            if level_price is None: return False
            if hasattr(level_price, 'item'): level_price = level_price.item()
            level_price = float(level_price)
            tolerance = 0.005
            price_min = level_price * (1 - tolerance)
            price_max = level_price * (1 + tolerance)
            cooldown_time = (datetime.now() - timedelta(hours=cooldown_hours)).isoformat()
            placeholder = "%s" if db_manager.is_postgres else "?"
            query = f"""SELECT timestamp FROM alert_history 
                        WHERE token_address = {placeholder} AND level_price BETWEEN {placeholder} AND {placeholder} AND timestamp > {placeholder}
                        LIMIT 1"""
            params = (signal['token_address'], price_min, price_max, cooldown_time)

        try:
            if db_manager.fetchone(query, params):
                self.logger.info(f"ğŸ”µ [COOLDOWN] Cooldown active for {signal['symbol']} ({signal_type}) for {cooldown_hours}h.")
                return True
            return False
        except Exception as e:
            self.logger.error(f"âŒ Error in has_recent_alert for {signal['symbol']}: {e}")
            return False
 
    async def detect_gem_momentum_signal(self, df_5min, token_info):
        """Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø§Ø®ØªØµØ§ØµÛŒ Ø¨Ø±Ø§ÛŒ Ø´Ú©Ø§Ø± ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ (Gem Hunter)."""
        
        # ===== Ú©Ø¯ Ø¬Ø¯ÛŒØ¯ Ø§Ø² Ø§ÛŒÙ†Ø¬Ø§ =====
        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù‡ ØªÙˆÚ©Ù† ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§Ø´Ù‡
        if len(df_5min) > 288:  # Ø¨ÛŒØ´ØªØ± Ø§Ø² 24 Ø³Ø§Ø¹Øª Ø¯Ø§Ø¯Ù‡ (288 Ú©Ù†Ø¯Ù„ 5 Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ)
            self.logger.info(f"â­ï¸ {token_info['symbol']}: Too old for GEM strategy ({len(df_5min)} candles)")
            return None
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù‡ Ù‚ÛŒÙ…Øª Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ Ú©Ù„ÛŒ Ø¨Ø§Ø´Ù‡
        if len(df_5min) > 12:  # Ø­Ø¯Ø§Ù‚Ù„ 1 Ø³Ø§Ø¹Øª Ø¯Ø§Ø¯Ù‡
            price_1h_ago = df_5min['close'].iloc[-12]
            current_price_check = df_5min['close'].iloc[-1]
            
            if current_price_check < price_1h_ago * 0.8:  # Ø§Ú¯Ø± Ø¨ÛŒØ´ Ø§Ø² 20% Ø§ÙØª Ø¯Ø§Ø´ØªÙ‡
                self.logger.info(f"ğŸ“‰ {token_info['symbol']}: Downtrend detected, skipping GEM signal")
                return None
        # ===== Ù¾Ø§ÛŒØ§Ù† Ú©Ø¯ Ø¬Ø¯ÛŒØ¯ =====
        
        current_price = df_5min['close'].iloc[-1]
        ath = df_5min['high'].max() # All-Time High Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø¯Ø±ÛŒØ§ÙØªÛŒ
        
        # --- Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Û²: Ø§Ù„Ú¯ÙˆÛŒ Ø´Ú©Ø³Øª Ù¾Ø³ Ø§Ø² ØªØ«Ø¨ÛŒØª (Consolidation Breakout) ---
        if len(df_5min) >= 12: # Ø­Ø¯Ø§Ù‚Ù„ Û± Ø³Ø§Ø¹Øª Ø¯Ø§Ø¯Ù‡ Ù„Ø§Ø²Ù… Ø§Ø³Øª
            last_12_candles = df_5min.iloc[-12:] # ÛŒÚ© Ø³Ø§Ø¹Øª Ø§Ø®ÛŒØ±
            high_1h = last_12_candles['high'].max()
            low_1h = last_12_candles['low'].min()
            range_pct = (high_1h - low_1h) / current_price if current_price > 0 else 0
            
            # Ø¢ÛŒØ§ Ù‚ÛŒÙ…Øª Ø¯Ø± ÛŒÚ© Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡ Ø¯Ø± ÛŒÚ© Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¨Ø§Ø±ÛŒÚ© (Ú©Ù…ØªØ± Ø§Ø² Û²Û°Ùª) ØªØ«Ø¨ÛŒØª Ø´Ø¯Ù‡ØŸ
            if range_pct < 0.20:
                # Ø¢ÛŒØ§ Ù‚ÛŒÙ…Øª Ø¯Ø± Ø­Ø§Ù„ Ø´Ú©Ø³ØªÙ† Ø³Ù‚Ù Ø§ÛŒÙ† Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø§Ø³ØªØŸ
                if current_price >= high_1h * 0.98:
                    self.logger.info(f"ğŸ’ {token_info['symbol']}: Potential 'Consolidation Breakout' detected.")
                    return self._create_gem_signal('GEM_BREAKOUT', token_info, current_price, {
                        "Consolidation Range": f"{range_pct:.1%}"
                    }, df_5min)
        
        return None

    def _create_gem_signal(self, signal_type, token_info, price, details, df):
        """ÛŒÚ© ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Gem Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
        from datetime import datetime
        
        signal = {
            'signal_type': signal_type,
            'token_address': token_info['address'],
            'pool_id': token_info['pool_id'],
            'symbol': token_info['symbol'],
            'current_price': price,
            'details': ", ".join([f"{k}: {v}" for k, v in details.items()]),
            'timestamp': datetime.now().isoformat()
        }
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† analysis_result Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ ØªØ§Ø¨Ø¹ Ø§Ø±Ø³Ø§Ù„ Ù‡Ø´Ø¯Ø§Ø±
        signal['analysis_result'] = {
            'metadata': {'symbol': token_info['symbol'], 'timeframe': 'minute', 'aggregate': '5'},
            'raw_data': {'dataframe': df, 'current_price': price},
            'technical_levels': {'zones': {'supply': [], 'demand': []}, 'fibonacci': None}
        }
        return signal
